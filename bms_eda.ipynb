{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f725643a",
   "metadata": {},
   "source": [
    "# Battery Management System Dataset - Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook performs a comprehensive exploratory data analysis on the Battery Management System (BMS) dataset from the `cleaned_dataset/data/` directory. The BMS dataset contains multiple CSV files with battery cycle data including current, voltage, and temperature measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fa265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541d1f1",
   "metadata": {},
   "source": [
    "## Load Data Files\n",
    "Loading all CSV files from the cleaned_dataset/data directory and combining them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data files from cleaned_dataset/data directory\n",
    "data_dir = Path('/home/harshit/Documents/bms/cleaned_dataset/data')\n",
    "csv_files = sorted(data_dir.glob('*.csv'))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files in the data directory\")\n",
    "print(f\"Files: {[f.name for f in csv_files[:5]]} ... and {len(csv_files) - 5} more\")\n",
    "\n",
    "# Load first file to understand structure\n",
    "first_df = pd.read_csv(csv_files[0])\n",
    "print(f\"\\nFirst file ({csv_files[0].name}) shape: {first_df.shape}\")\n",
    "print(f\"Columns: {first_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(first_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e515c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine all CSV files\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['file_id'] = csv_file.stem  # Add file identifier\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "print(f\"Total rows: {len(combined_df):,}\")\n",
    "print(f\"Total columns: {len(combined_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256813b0",
   "metadata": {},
   "source": [
    "## Display Basic Data Information\n",
    "Examining the structure, data types, and content of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(combined_df.info())\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FIRST FEW ROWS\")\n",
    "print(\"=\" * 80)\n",
    "print(combined_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538abf5",
   "metadata": {},
   "source": [
    "## Generate Descriptive Statistics\n",
    "Statistical summary of numerical features including mean, median, std, and quantiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a50c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "print(\"=\" * 80)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(combined_df.describe().T)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA TYPES COUNT\")\n",
    "print(\"=\" * 80)\n",
    "print(combined_df.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7c441",
   "metadata": {},
   "source": [
    "## Check for Missing Values\n",
    "Identifying missing values in the dataset and visualizing their distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d120220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_values = combined_df.isnull().sum()\n",
    "missing_percent = (combined_df.isnull().sum() / len(combined_df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': combined_df.columns,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing Percentage': missing_percent.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df)\n",
    "print(f\"\\nTotal missing values: {combined_df.isnull().sum().sum():,}\")\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_values.sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_percent[missing_percent > 0].sort_values(ascending=False).plot(kind='barh')\n",
    "    plt.xlabel('Percentage Missing (%)')\n",
    "    plt.title('Missing Values Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nâœ“ No missing values detected in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e45aca",
   "metadata": {},
   "source": [
    "## Visualize Data Distributions\n",
    "Creating histograms, box plots, and density plots for numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9259528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical columns only (excluding file_id)\n",
    "numerical_cols = combined_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Create distribution plots for numerical columns\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        axes[idx].hist(combined_df[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10faeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for numerical columns\n",
    "if len(numerical_cols) > 0:\n",
    "    fig, axes = plt.subplots(1, len(numerical_cols), figsize=(15, 5))\n",
    "    if len(numerical_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        axes[idx].boxplot(combined_df[col].dropna())\n",
    "        axes[idx].set_title(f'Box Plot of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel(col)\n",
    "        axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7bca0",
   "metadata": {},
   "source": [
    "## Explore Correlations and Relationships\n",
    "Creating correlation matrices and heatmaps to identify relationships between variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix (excluding file_id)\n",
    "numerical_df = combined_df.select_dtypes(include=[np.number])\n",
    "\n",
    "if len(numerical_df.columns) > 1:\n",
    "    correlation_matrix = numerical_df.corr()\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(correlation_matrix)\n",
    "    \n",
    "    # Find strong correlations\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STRONG CORRELATIONS (|r| > 0.7)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    strong_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.7:\n",
    "                strong_corr.append({\n",
    "                    'Feature 1': correlation_matrix.columns[i],\n",
    "                    'Feature 2': correlation_matrix.columns[j],\n",
    "                    'Correlation': corr_value\n",
    "                })\n",
    "    \n",
    "    if strong_corr:\n",
    "        strong_corr_df = pd.DataFrame(strong_corr).sort_values('Correlation', key=abs, ascending=False)\n",
    "        print(strong_corr_df)\n",
    "    else:\n",
    "        print(\"No strong correlations found (|r| > 0.7)\")\n",
    "else:\n",
    "    print(\"Not enough numerical columns to calculate correlation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abcdae5",
   "metadata": {},
   "source": [
    "## Data Quality Summary\n",
    "Summary of key data quality metrics and insights.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
